# This is not a real configuration file that you could use with ensemble_scripts
# This is merely for the sake of understanding
# The final configuration is ensemble_no21.conf, use it instead

# video baseline models
1. video_relabel_combine_chain
   video level combine chain model, add the most confident tag predicted by the current model to the labels when loss<10.0
   youtube-8m-zhangteng.video_level_models.MoeMix4Model
   #moe_mixtures is 4, #combination_layers is 3, #chain_relu_cells is 100
   GAP in validate1 is 0.8088 at step 14863
   
2. video_very_deep_combine_chain

# lstm baseline models
3. lstmmemory_cell1024_layer2_moe8
4. lstmmemory_cell2048_layer2_moe4
5. lstmparallelfinaloutput1024_moe8
6. lstmparallelmemory1024_moe8
7. lstmgate_cell1024_layer1_moe8
   lstm and moe model, using scalar input and forget gate in lstm cell
   youtube-8m-zhangteng.frame_level_models.LstmGateModel
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8148 at step 151107
8. lstmglu2_cell1024_layer1_moe8
   lstm and moe model, using scalar input and forget gate in lstm cell, add forward immediate input memory (with its own input and forget gate) to lstm cell
   youtube-8m-zhangteng.frame_level_models.LstmGlu2Model
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8152 at step 132334
9. lstmbiglu_cell1024_layer1_moe8
   lstm and moe model, using scalar input and forget gate in lstm cell, add bi-directional immediate input memory (with its own input and forget gate) to lstm cell
   youtube-8m-zhangteng.frame_level_models.LstmBigluModel
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8131 at step 130983
10. biunilstm1024_moe4
11. lstm_random_mean_moe8
   lstm and moe model, randomly select half of all frames to create new samples to train
   youtube-8m-zhangteng.frame_level_models.LstmRandomModel + youtube-8m-zhangteng.video_level_models.MoeModel
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 2, augmentation times for each sample is 16 when eval and inference
   GAP in validate1 is 0.8145 at step 145850
12. lstm_shortlayers_moe8
   lstm and moe model, divide sample into several clips with fixed frames, use one lstm to model intra-clip structure, use another lstm to model inter-clip structure
   youtube-8m-zhangteng.frame_level_models.LstmLayerModel + youtube-8m-zhangteng.video_level_models.MoeModel
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 2, #clip_length_frames is 10
   GAP in validate1 is 0.8145 at step 107188
13. framehop_lstm
14. cnnlstmmemory1024_moe8

# attention models
15. attentionlstm_moe4
16. lstmattlstm1024_moe8
17. lstm_attention8_max
   lstm and moe model, use frame inputs and lstm outputs to calculate weight of each frame, then get the attention vector using a weighted sum of lstm outputs, then make predictions using moe model, repeat several times, take the maximum prediction of these times as the final prediction
   youtube-8m-zhangteng.frame_level_models.LstmExtendModel + youtube-8m-zhangteng.video_level_models.MoeExtendModel
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 2, #attention_repeat_times is 8
   GAP in validate1 is 0.8177 at step 181785
18. lstm2_attention8_max
   lstm and moe model, use frame inputs and one lstm outputs to calculate weight of each frame, then get the attention vector using a weighted sum of another lstm outputs, then make predictions using moe model, repeat several times, take the maximum prediction of these times as the final prediction
   youtube-8m-zhangteng.frame_level_models.InputExtendModel + youtube-8m-zhangteng.video_level_models.MoeExtendModel
   #moe_mixtures is 8, #lstm_cells is 1024, #lstm_layers is 2, #attention_repeat_times is 4
   GAP in validate1 is 0.8106 at step 197005
   
19. lstm_positional_attention8max

# multiple sub model joined by deep combine chain
20. cnn_deep_combine_chain
21. deep_cnn_deep_combine_chain
22. lstm_cnn_deep_combine_chain
23. multilstmmemory1024_moe4_deep_chain
24. lstmmem1024_layer2_moe4_deep_combine_chain_add_length
25. multires_lstm_deep_combine_chain
26. lstm_gate_multiscale4_moe4
   cnn-lstm and moe model, use a deep cnn to get multiscale representions at different layers, then use a lstm described in model #7 and moe model at each layer to make predictions, take the mean prediction of these layers as the final prediction
   youtube-8m-zhangteng.frame_level_models.LstmMultiscale2Model
   #moe_mixtures is 4, #cnn_layers is 4, #cnn_cells is [256,256,512], #cnn_fields is [1,2,3] , #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8166 at step 193803
27. lstm_multiscale4_moe4
   cnn-lstm and moe model, use a deep cnn to get multiscale representions at different layers, then use a basic lstm and moe model at each layer to make predictions, take the mean prediction of these layers as the final prediction
   youtube-8m-zhangteng.frame_level_models.LstmMultiscaleModel
   #moe_mixtures is 4, #cnn_layers is 4, #cnn_cells is [256,256,512], #cnn_fields is [1,2,3] , #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8223 at step 231916
   
# bagging and boosting models
28. video_dcc_bagging
29. video_cc_structure_bagging/ensemble_matrix_model
   the video_cc_structure_bagging model is composed of four sub models:
   29.1 video_notzero_combine_chain
       video level combine chain model, use both support_predictions and (1-support_predictions) as label dependence at each combination layer
	   youtube-8m-zhangteng.video_level_models.MoeMix4Model
	   #moe_mixtures is 4, #combination_layers is 3, #chain_relu_cells is 100
	   GAP in validate1 is 0.8099 at step 14668
   29.2 video_weight_combine_chain
       video level combine chain model, multiply loss of positive labels by 10, while multiply loss of negative labels by 1
	   youtube-8m-zhangteng.video_level_models.MoeMix4Model
	   #moe_mixtures is 4, #combination_layers is 3, #chain_relu_cells is 100
	   GAP in validate1 is 0.8079 at step 17415
   29.3 video_knowledge_combine_chain
       video level combine chain model, use both support_predictions and top-level verticals of support_predictions as label dependence at each combination layer
	   youtube-8m-zhangteng.video_level_models.MoeKnowledgeModel
	   #moe_mixtures is 4, #combination_layers is 3, #chain_relu_cells is 100
	   GAP in validate1 is 0.8108 at step 9606
   29.4 video_softmax_combine_chain
       video level combine chain model, use sigmiod model to predict the first 3000 labels, and use softmax model to predict the rest 1716 labels
	   youtube-8m-zhangteng.video_level_models.MoeSoftmaxModel
	   #moe_mixtures is 4, #combination_layers is 3, #chain_relu_cells is 100
	   GAP in validate1 is 0.8102 at step 9501
	   
   GAP of ensemble_matrix_model in validate2 is 
	   
30. video_dcc_boosting_discardhopeless/ensemble_matrix_model
31. video_dcc_boosting/ensemble_matrix_model
32. video_dcc_boosting_weightclip/ensemble_matrix_model
33. cnn_deep_combine_chain_bagging/ensemble_matrix_model
34. cnn_deep_combine_chain_boosting/ensemble_attention_matrix_model
35. lstmattention8max_bagging/ensemble_matrix_model
36. lstmattention8max_boosting/ensemble_attention_matrix_model
37. lstmparalleloutput_bagging/ensemble_mean_model
38. lstmparalleloutput_boosting_weightclip/ensemble_matrix_model

# distillation models
39. distillation_video_dcc_noise
40. distillation_cnn_dcc_boosting/sub_model_1
41. distillation_lstmcnn_dcc_boosting/sub_model_1
42. distillation_lstmparalleloutput_boosting/sub_model_1
43. distillation_multilstm_dcc_boosting/sub_model_1
44. distillation_multiscale_cnnlstm_boosting/sub_model_1
45. distillation_video_dcc_bagging/ensemble_matrix_model
46. distillation_video_dcc_boosting/ensemble_matrix_model

# cascade models
47. distillchain_video_dcc
48. distillchain_video_norm_moe8
   video level moe model, use ditill labels as label dependence, normalize the label dependence with the summation of ditill labels
   youtube-8m-zhangteng.video_level_models.MoeDistillChainNorm2Model
   #moe_mixtures is 8, #chain_relu_cells is 256
   GAP in validate1 is 0.8260 at step 13412
49. distillchain_lstm_gate_moe8
   lstm and moe model, use lstm cell described in model #7 in frame level, use ditill labels as label dependence in video level
   youtube-8m-zhangteng.frame_level_models.LstmGateModel + youtube-8m-zhangteng.video_level_models.MoeDistillChainModel
   #moe_mixtures is 8, #chain_relu_cells is 256, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8293 at step 63344
50. distillchain_cnn_dcc
51. distillchain_cnndcc_layer2moe4
   cnn and deep combine chain model, use ditill labels as label dependence only in the first combination layer
   youtube-8m-zhangteng.frame_level_models.CnnDCCDistillChainModel
   #moe_mixtures is 4, #chain_relu_cells is 256, #combination_layers=2
   GAP in validate1 is 0.8241 at step 188273
52. distillchain_lstm_attention8max
   lstm and moe model as described in model #17, use ditill labels as label dependence on each attention output vector
   youtube-8m-zhangteng.frame_level_models.LstmExtendModel + youtube-8m-zhangteng.video_level_models.MoeExtendDistillChainModel
   #moe_mixtures is 8, #chain_relu_cells is 256, #attention_repeat_times is 8, #lstm_cells is 1024, #lstm_layers is 2
   GAP in validate1 is 0.8298 at step 74796
53. distillchain_lstm_moe8
   lstm and moe model as described in model #3, use ditill labels as label dependence in video level
   youtube-8m-zhangteng.frame_level_models.LstmModel + youtube-8m-zhangteng.video_level_models.MoeDistillChainModel
   #moe_mixtures is 8, #chain_relu_cells is 256, #lstm_cells is 1024, #lstm_layers is 2
   GAP in validate1 is 0.8283 at step 49873
54. distillchain_lstm_multiscale_layer2_moe8
   cnn-lstm and moe model as described in model #27, use ditill labels as label dependence in each cnn layer
   youtube-8m-zhangteng.frame_level_models.LstmMultiscaleDitillChainModel
   #moe_mixtures is 4, #chain_relu_cells is 256, #cnn_layers is 2, #cnn_cells is [256,256,512], #cnn_fields is [1,2,3] , #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8313 at step 103725
55. distillchain_lstm_multiscale_layer4_moe8
   cnn-lstm and moe model as described in model #27, use ditill labels as label dependence in each cnn layer
   youtube-8m-zhangteng.frame_level_models.LstmMultiscaleDitillChainModel
   #moe_mixtures is 4, #chain_relu_cells is 256, #cnn_layers is 4, #cnn_cells is [196,196,392], #cnn_fields is [1,2,3] , #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8320 at step 102004
56. distillchain_lstmcnn_dcc
57. distillsplit_lstm_gate_moe8
   lstm and moe model, use lstm cell described in model #7 in frame level, use the last 3716 ditill labels as label dependence in video level to redict the rest 1000 labels, concat the 3716 ditill labels and 1000 predicted labels as the final predictions
   youtube-8m-zhangteng.frame_level_models.LstmGateModel + youtube-8m-zhangteng.video_level_models.MoeDistillSplitModel
   #moe_mixtures is 8, #chain_relu_cells is 256, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8257 at step 130570
58. distillchain_v2_video_dcc
59. distillchain_v2_lstmattention8max
60. distillchain_v2_lstmcnn_dcc
61. distillchain_v2_lstm_gate_moe8
   lstm and moe model as described in model #49, but on a new distillation training dataset
   youtube-8m-zhangteng.frame_level_models.LstmGateModel + youtube-8m-zhangteng.video_level_models.MoeDistillChainModel
   #moe_mixtures is 8, #chain_relu_cells is 256, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8273 at step 73400
62. distillchain_v2_lstm_glu2_moe8
   lstm and moe model as described in model #49, but use lstm cell as described in model #8, and on a new distillation training dataset
   youtube-8m-zhangteng.frame_level_models.LstmGlu2Model + youtube-8m-zhangteng.video_level_models.MoeDistillChainModel
   #moe_mixtures is 8, #chain_relu_cells is 256, #lstm_cells is 1024, #lstm_layers is 1
   GAP in validate1 is 0.8280 at step 72525
63. distillchain_v2_multilstm_dcc
64. distillchain_v2_multiscale_cnnlstm
65. distillchain_v2_lstmparalleloutput
66. distillchain_v2_boost_lstmparalleloutput
67. videochain/distillchain_v2_video_dcc_1
68. videochain/distillchain_v2_video_dcc_2
69. videochain/distillchain_v2_video_dcc_3
70. videochain/distillchain_v2_video_dcc_4
71. videochain/distillchain_v2_video_dcc_5
72. hybridchain/distillchain_v2_video_dcc
73. hybridchain/distillchain_v2_cnn_dcc
74. hybridchain/distillchain_v2_lstmparalleloutput
