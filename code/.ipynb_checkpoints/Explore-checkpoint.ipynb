{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15a5f5c8-3fdc-4693-919a-2fc9de2ecee2",
    "_uuid": "22217d65c9bfadd0e948a49b74a7ec75cba4437f"
   },
   "source": [
    "# This notebook explores the data (TFRecord format) using a subsample of the YouTube-8M video & frame-level data. To work with the entire dataset, please refer to the Starter code on the [YouTube-8M github repo](https://github.com/google/youtube-8m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame', 'models', 'video']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../v2\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validate1644.tfrecord', 'validate3043.tfrecord', 'train3529.tfrecord', 'validate0523.tfrecord', 'train3607.tfrecord', 'train0276.tfrecord', 'test1306.tfrecord', 'train0979.tfrecord', 'train3702.tfrecord', 'train0667.tfrecord', 'test0274.tfrecord', 'test2246.tfrecord', 'train3220.tfrecord', 'validate2394.tfrecord', 'validate1937.tfrecord', 'test3701.tfrecord', 'test0152.tfrecord', 'test1553.tfrecord', 'validate3489.tfrecord', 'validate0638.tfrecord', 'validate1116.tfrecord', 'test2855.tfrecord', 'test2501.tfrecord', 'train2495.tfrecord', 'train2160.tfrecord', 'train0477.tfrecord', 'validate0676.tfrecord', 'train1087.tfrecord', 'validate0797.tfrecord', 'train0274.tfrecord', 'test1956.tfrecord', 'train1805.tfrecord', 'validate0259.tfrecord', 'train2950.tfrecord', 'train0352.tfrecord', 'validate0876.tfrecord', 'train0503.tfrecord', 'validate1219.tfrecord', 'validate0267.tfrecord', 'train0830.tfrecord', 'train0208.tfrecord', 'test3657.tfrecord', 'train2791.tfrecord', 'test3462.tfrecord', 'validate1831.tfrecord', 'train1745.tfrecord', 'train1110.tfrecord', 'test0162.tfrecord', 'train1646.tfrecord', 'validate2094.tfrecord', 'test1616.tfrecord', 'test2636.tfrecord', 'test3062.tfrecord', 'validate0052.tfrecord', 'train2896.tfrecord', 'test0100.tfrecord', 'test3508.tfrecord', 'validate0780.tfrecord', 'train0111.tfrecord', 'test3213.tfrecord', 'train2902.tfrecord', 'train2161.tfrecord', 'validate3731.tfrecord', 'validate2164.tfrecord', 'test2022.tfrecord', 'validate1395.tfrecord', 'test0473.tfrecord', 'validate0842.tfrecord', 'validate3432.tfrecord', 'test2057.tfrecord', 'test3076.tfrecord', 'train2072.tfrecord', 'validate1169.tfrecord', 'test2108.tfrecord', 'validate3182.tfrecord', 'train3551.tfrecord', 'train3560.tfrecord', 'test3456.tfrecord', 'test0285.tfrecord', 'validate3343.tfrecord', 'train0093.tfrecord', 'validate3115.tfrecord', 'test3134.tfrecord', 'test0735.tfrecord', 'train1864.tfrecord', 'train2154.tfrecord', '2_frame_validate_download_plan.json', 'test2069.tfrecord', 'test2226.tfrecord', 'test1563.tfrecord', 'test0397.tfrecord', 'test0474.tfrecord', 'train0637.tfrecord', 'validate0455.tfrecord', 'validate1704.tfrecord', 'train3519.tfrecord', 'train3749.tfrecord', '2_frame_train_download_plan.json', 'validate0955.tfrecord', 'train2722.tfrecord', 'test1114.tfrecord', 'test2901.tfrecord', 'validate1210.tfrecord', 'validate0024.tfrecord', 'train3012.tfrecord', 'validate1932.tfrecord', 'test2560.tfrecord', 'train0434.tfrecord', 'test1818.tfrecord', 'validate2525.tfrecord', 'validate0701.tfrecord', 'validate2501.tfrecord', 'validate0965.tfrecord', 'test0858.tfrecord', 'test1630.tfrecord', 'test3392.tfrecord', 'train0580.tfrecord', 'test3212.tfrecord', 'validate1769.tfrecord', 'train3622.tfrecord', '2_frame_test_download_plan.json', 'train3477.tfrecord', 'validate2517.tfrecord']\n",
      "['validate1644.tfrecord', 'validate3043.tfrecord', 'train3529.tfrecord', 'validate0523.tfrecord', 'train3607.tfrecord', 'train0276.tfrecord', 'test1306.tfrecord', 'train0979.tfrecord', 'train3702.tfrecord', 'train0667.tfrecord', 'test0274.tfrecord', 'test2246.tfrecord', 'train3220.tfrecord', 'validate2394.tfrecord', 'validate1937.tfrecord', 'test3701.tfrecord', 'test0152.tfrecord', 'test1553.tfrecord', 'validate3489.tfrecord', 'validate0638.tfrecord', 'validate1116.tfrecord', 'test2855.tfrecord', 'test2501.tfrecord', 'train2495.tfrecord', 'train2160.tfrecord', 'train0477.tfrecord', 'validate0676.tfrecord', 'train1087.tfrecord', 'validate0797.tfrecord', 'train0274.tfrecord', 'test1956.tfrecord', 'train1805.tfrecord', 'validate0259.tfrecord', 'train2950.tfrecord', 'train0352.tfrecord', 'validate0876.tfrecord', 'train0503.tfrecord', 'validate1219.tfrecord', 'validate0267.tfrecord', 'train0830.tfrecord', 'train0208.tfrecord', 'test3657.tfrecord', 'train2791.tfrecord', 'test3462.tfrecord', 'validate1831.tfrecord', 'train1745.tfrecord', 'train1110.tfrecord', 'test0162.tfrecord', 'train1646.tfrecord', 'validate2094.tfrecord', '2_video_test_download_plan.json', 'test1616.tfrecord', '2_video_validate_download_plan.json', 'test2636.tfrecord', 'test3062.tfrecord', 'validate0052.tfrecord', 'train2896.tfrecord', 'test0100.tfrecord', 'test3508.tfrecord', 'validate0780.tfrecord', 'train0111.tfrecord', 'test3213.tfrecord', 'train2902.tfrecord', 'train2161.tfrecord', 'validate3731.tfrecord', 'validate2164.tfrecord', 'test2022.tfrecord', 'validate1395.tfrecord', 'test0473.tfrecord', 'validate0842.tfrecord', 'validate3432.tfrecord', 'test2057.tfrecord', 'test3076.tfrecord', 'train2072.tfrecord', 'validate1169.tfrecord', 'test2108.tfrecord', 'validate3182.tfrecord', 'train3551.tfrecord', 'train3560.tfrecord', 'test3456.tfrecord', 'test0285.tfrecord', 'validate3343.tfrecord', 'train0093.tfrecord', 'validate3115.tfrecord', 'test3134.tfrecord', 'test0735.tfrecord', 'train1864.tfrecord', 'train2154.tfrecord', 'test2069.tfrecord', 'test2226.tfrecord', 'test1563.tfrecord', 'test0397.tfrecord', 'test0474.tfrecord', '2_video_train_download_plan.json', 'train0637.tfrecord', 'validate0455.tfrecord', 'validate1704.tfrecord', 'train3519.tfrecord', 'train3749.tfrecord', 'validate0955.tfrecord', 'train2722.tfrecord', 'test1114.tfrecord', 'test2901.tfrecord', 'validate1210.tfrecord', 'validate0024.tfrecord', 'train3012.tfrecord', 'validate1932.tfrecord', 'test2560.tfrecord', 'train0434.tfrecord', 'test1818.tfrecord', 'validate2525.tfrecord', 'validate0701.tfrecord', 'validate2501.tfrecord', 'validate0965.tfrecord', 'test0858.tfrecord', 'test1630.tfrecord', 'test3392.tfrecord', 'train0580.tfrecord', 'test3212.tfrecord', 'validate1769.tfrecord', 'train3622.tfrecord', 'train3477.tfrecord', 'validate2517.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../v2/frame\"))\n",
    "print(os.listdir(\"../v2/video\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f22c36cf-f788-4edc-9a88-32c116fa4cb8",
    "_uuid": "d1656e711254f02e2479e2f95704e3dd42949607"
   },
   "outputs": [],
   "source": [
    "#Loading libraries & datasets\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "video_lvl_record = \"../v2/video/train00.tfrecord\"\n",
    "frame_lvl_record = \"../v2/frame/train00.tfrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d80e50b4-692b-480d-a3fd-d59cf226de19",
    "_uuid": "8bd33285e392f106994effc1a46644d073dcc5fc"
   },
   "source": [
    "# Let's start with the video-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "7b19d838-f9db-4e22-8420-16b0d93f16fe",
    "_uuid": "16a62102bef4da3c6f5de8176267f7a5b0e74776"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "../v2/video/train00.tfrecord; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9b4de5687803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_lvl_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/.env/lib/python3.5/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36mtf_record_iterator\u001b[0;34m(path, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     reader = pywrap_tensorflow.PyRecordReader_New(\n\u001b[0;32m---> 74\u001b[0;31m         compat.as_bytes(path), 0, compat.as_bytes(compression_type), status)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/.env/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ../v2/video/train00.tfrecord; No such file or directory"
     ]
    }
   ],
   "source": [
    "vid_ids = []\n",
    "labels = []\n",
    "mean_rgb = []\n",
    "mean_audio = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(video_lvl_record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "    vid_ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "    labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "    mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n",
    "    mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02c8c33e-c5d9-4fe4-ac14-20a3d689f877",
    "_uuid": "d7e308317de941794b45c45d98945d07f669a8f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of videos in this tfrecord: ',len(mean_rgb))\n",
    "print('Picking a youtube video id:',vid_ids[13])\n",
    "print('First 20 features of a youtube video (',vid_ids[13],'):')\n",
    "print(mean_rgb[13][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10154919-12f9-42e7-b1ea-a1b9c5c61247",
    "_uuid": "50ddbae66c152eb53fc8c163e82619438af57084"
   },
   "source": [
    "As described on the [YouTube8M download page](https://research.google.com/youtube8m/video_id_conversion.html), for privacy reasons, the video `id` has been randomly generated and does not directly correspond to the actual YouTube video id. To convert the `id` into the actua YouTube video id, we follow link: [http://data.yt8m.org/2/j/i/1r/1r00.js](http://data.yt8m.org/2/j/i/1r/1r00.js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "17d9feba-98e3-4106-8e7a-9da233c34de5",
    "_uuid": "862f198e022731fcc3a91e03c1bed5497fee35ec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With that video id, we can play the video\n",
    "YouTubeVideo('-QM5ooctj0w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ebf04fd-0507-461b-92c8-a63527736203",
    "_uuid": "1cb1866f0259916ea4a819fdc616baff3841fd77"
   },
   "source": [
    "# Now, let's read the frame-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "75e41de0-a768-485e-8246-92f40ec06aed",
    "_uuid": "379dc32f4543f99cb1b373e28398aface44031c2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# due to execution time, we're only going to read the first video\n",
    "\n",
    "feat_rgb = []\n",
    "feat_audio = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(frame_lvl_record):        \n",
    "    tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n",
    "    sess = tf.InteractiveSession()\n",
    "    rgb_frame = []\n",
    "    audio_frame = []\n",
    "    # iterate through frames\n",
    "    for i in range(n_frames):\n",
    "        rgb_frame.append(tf.cast(tf.decode_raw(\n",
    "                tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                       ,tf.float32).eval())\n",
    "        audio_frame.append(tf.cast(tf.decode_raw(\n",
    "                tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                       ,tf.float32).eval())\n",
    "        \n",
    "        \n",
    "    sess.close()\n",
    "    feat_rgb.append(rgb_frame)\n",
    "    feat_audio.append(audio_frame)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c09c3c2f-749f-4ebf-a159-d2efcc9fe1ac",
    "_uuid": "a0922db2db6058deca67cba38204f705010be568",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The first video has %d frames' %len(feat_rgb[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f8c087f0-1a4d-49d0-b0ed-d8747d85d17a",
    "_uuid": "612a50a77785f90d916899917c1a961035884450"
   },
   "source": [
    "# Now let's explore the labels\n",
    "\n",
    "First, we'll find the most commonly used labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02872613-bef2-4a77-a924-55a0f7b31adb",
    "_uuid": "0abc6b55f0e4a268dc92918b8715c1bc4484b40c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "08cf2a57-6eec-444a-b280-e86a5e026cdf",
    "_uuid": "1367abe58fd3c94d63312773cabdce5af606d794",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_2018 = pd.read_csv('../input/label_names_2018.csv')\n",
    "print(\"we have {} unique labels in the dataset\".format(len(labels_2018['label_name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d159438b-ddcf-4d78-87cb-3e479404f261",
    "_uuid": "44daa93d3c7acb4fed93ef7b11eac2d4718a5f5b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "from collections import Counter\n",
    "label_mapping = pd.read_csv('../input/label_names_2018.csv',header=0,index_col=0,squeeze=True).T.to_dict()\n",
    "\n",
    "top_n = Counter([item for sublist in labels for item in sublist]).most_common(n)\n",
    "top_n_labels = [int(i[0]) for i in top_n]\n",
    "top_n_label_names = [label_mapping[x] for x in top_n_labels]\n",
    "top_n_label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1687471-951c-4028-a680-386cf22494b1",
    "_uuid": "2d43fd67abda2e0ae7b2058218ca8e2fb57962ca"
   },
   "source": [
    "And plot the relationships between each of these top labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a271ee2-3efc-4aee-b364-b0ece9157b0f",
    "_uuid": "2d5bc349aef74f1a7158b65498662c10010edddf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "G=nx.Graph()\n",
    "\n",
    "G.clear()\n",
    "for list_of_nodes in labels:\n",
    "    filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels))  \n",
    "    for node1,node2 in list(combinations(filtered_nodes,2)): \n",
    "        node1_name = label_mapping[node1]\n",
    "        node2_name = label_mapping[node2]\n",
    "        G.add_node(node1_name)\n",
    "        G.add_node(node2_name)\n",
    "        G.add_edge(node1_name, node2_name)\n",
    "\n",
    "nx.draw_networkx(G,font_size=\"10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "66ba94f4-5330-4e29-b42a-52aaa3fcc188",
    "_uuid": "ae6ff68ffbc6e79d7da4e8162927eeb25115ad54"
   },
   "source": [
    "And a t-SNE plot on the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2639ecc0-0de8-44c4-88b6-864407e62400",
    "_uuid": "02d9bcaeaa5ad450ce68d43ef620cf59b4f39f60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "mean_rgb_top_n = []\n",
    "labels_for_tsne = []\n",
    "# filtering mean_rgb so it only contains top n labels\n",
    "for idx, list_of_nodes in enumerate(labels):\n",
    "    for node in list_of_nodes:\n",
    "        if node in top_n_labels:\n",
    "            mean_rgb_top_n.append(mean_rgb[idx])\n",
    "            labels_for_tsne.append(node)\n",
    "\n",
    "\n",
    "X_embedded = TSNE(n_components=2, random_state=0).fit_transform(mean_rgb_top_n) \n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "handles = []\n",
    "for indx, color in enumerate(colors):\n",
    "    this_label = top_n_labels[indx]\n",
    "    X_embedded_filtered = X_embedded[np.array([x==this_label for x in labels_for_tsne])]\n",
    "    handles.append(ax.scatter(X_embedded_filtered[:, 0], X_embedded_filtered[:, 1], c=color, marker=\"o\",edgecolor='none'))\n",
    "\n",
    "ax.legend(handles, top_n_labels)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
